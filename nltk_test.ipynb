{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f33635a-41de-4989-a0e6-12499ec55f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ff2ccc-e52f-4e66-892c-208990a42540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__getattr__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_arff_parser',\n",
       " '_base',\n",
       " '_california_housing',\n",
       " '_covtype',\n",
       " '_kddcup99',\n",
       " '_lfw',\n",
       " '_olivetti_faces',\n",
       " '_openml',\n",
       " '_rcv1',\n",
       " '_samples_generator',\n",
       " '_species_distributions',\n",
       " '_svmlight_format_fast',\n",
       " '_svmlight_format_io',\n",
       " '_twenty_newsgroups',\n",
       " 'clear_data_home',\n",
       " 'dump_svmlight_file',\n",
       " 'fetch_20newsgroups',\n",
       " 'fetch_20newsgroups_vectorized',\n",
       " 'fetch_california_housing',\n",
       " 'fetch_covtype',\n",
       " 'fetch_kddcup99',\n",
       " 'fetch_lfw_pairs',\n",
       " 'fetch_lfw_people',\n",
       " 'fetch_olivetti_faces',\n",
       " 'fetch_openml',\n",
       " 'fetch_rcv1',\n",
       " 'fetch_species_distributions',\n",
       " 'get_data_home',\n",
       " 'load_breast_cancer',\n",
       " 'load_diabetes',\n",
       " 'load_digits',\n",
       " 'load_files',\n",
       " 'load_iris',\n",
       " 'load_linnerud',\n",
       " 'load_sample_image',\n",
       " 'load_sample_images',\n",
       " 'load_svmlight_file',\n",
       " 'load_svmlight_files',\n",
       " 'load_wine',\n",
       " 'make_biclusters',\n",
       " 'make_blobs',\n",
       " 'make_checkerboard',\n",
       " 'make_circles',\n",
       " 'make_classification',\n",
       " 'make_friedman1',\n",
       " 'make_friedman2',\n",
       " 'make_friedman3',\n",
       " 'make_gaussian_quantiles',\n",
       " 'make_hastie_10_2',\n",
       " 'make_low_rank_matrix',\n",
       " 'make_moons',\n",
       " 'make_multilabel_classification',\n",
       " 'make_regression',\n",
       " 'make_s_curve',\n",
       " 'make_sparse_coded_signal',\n",
       " 'make_sparse_spd_matrix',\n",
       " 'make_sparse_uncorrelated',\n",
       " 'make_spd_matrix',\n",
       " 'make_swiss_roll',\n",
       " 'textwrap']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1a6a372-de73-46ff-b0e4-a08822374081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ARLSTem',\n",
       " 'ARLSTem2',\n",
       " 'AbstractLazySequence',\n",
       " 'AffixTagger',\n",
       " 'AlignedSent',\n",
       " 'Alignment',\n",
       " 'AnnotationTask',\n",
       " 'ApplicationExpression',\n",
       " 'Assignment',\n",
       " 'BigramAssocMeasures',\n",
       " 'BigramCollocationFinder',\n",
       " 'BigramTagger',\n",
       " 'BinaryMaxentFeatureEncoding',\n",
       " 'BlanklineTokenizer',\n",
       " 'BllipParser',\n",
       " 'BottomUpChartParser',\n",
       " 'BottomUpLeftCornerChartParser',\n",
       " 'BottomUpProbabilisticChartParser',\n",
       " 'Boxer',\n",
       " 'BrillTagger',\n",
       " 'BrillTaggerTrainer',\n",
       " 'CFG',\n",
       " 'CRFTagger',\n",
       " 'CfgReadingCommand',\n",
       " 'ChartParser',\n",
       " 'ChunkParserI',\n",
       " 'ChunkScore',\n",
       " 'Cistem',\n",
       " 'ClassifierBasedPOSTagger',\n",
       " 'ClassifierBasedTagger',\n",
       " 'ClassifierI',\n",
       " 'ConcordanceIndex',\n",
       " 'ConditionalExponentialClassifier',\n",
       " 'ConditionalFreqDist',\n",
       " 'ConditionalProbDist',\n",
       " 'ConditionalProbDistI',\n",
       " 'ConfusionMatrix',\n",
       " 'ContextIndex',\n",
       " 'ContextTagger',\n",
       " 'ContingencyMeasures',\n",
       " 'CoreNLPDependencyParser',\n",
       " 'CoreNLPParser',\n",
       " 'CrossValidationProbDist',\n",
       " 'DRS',\n",
       " 'DecisionTreeClassifier',\n",
       " 'DefaultTagger',\n",
       " 'DependencyEvaluator',\n",
       " 'DependencyGrammar',\n",
       " 'DependencyGraph',\n",
       " 'DependencyProduction',\n",
       " 'DictionaryConditionalProbDist',\n",
       " 'DictionaryProbDist',\n",
       " 'DiscourseTester',\n",
       " 'DrtExpression',\n",
       " 'DrtGlueReadingCommand',\n",
       " 'ELEProbDist',\n",
       " 'EarleyChartParser',\n",
       " 'Expression',\n",
       " 'FStructure',\n",
       " 'FeatDict',\n",
       " 'FeatList',\n",
       " 'FeatStruct',\n",
       " 'FeatStructReader',\n",
       " 'Feature',\n",
       " 'FeatureBottomUpChartParser',\n",
       " 'FeatureBottomUpLeftCornerChartParser',\n",
       " 'FeatureChartParser',\n",
       " 'FeatureEarleyChartParser',\n",
       " 'FeatureIncrementalBottomUpChartParser',\n",
       " 'FeatureIncrementalBottomUpLeftCornerChartParser',\n",
       " 'FeatureIncrementalChartParser',\n",
       " 'FeatureIncrementalTopDownChartParser',\n",
       " 'FeatureTopDownChartParser',\n",
       " 'FreqDist',\n",
       " 'HTTPPasswordMgrWithDefaultRealm',\n",
       " 'HeldoutProbDist',\n",
       " 'HiddenMarkovModelTagger',\n",
       " 'HiddenMarkovModelTrainer',\n",
       " 'HunposTagger',\n",
       " 'IBMModel',\n",
       " 'IBMModel1',\n",
       " 'IBMModel2',\n",
       " 'IBMModel3',\n",
       " 'IBMModel4',\n",
       " 'IBMModel5',\n",
       " 'ISRIStemmer',\n",
       " 'ImmutableMultiParentedTree',\n",
       " 'ImmutableParentedTree',\n",
       " 'ImmutableProbabilisticMixIn',\n",
       " 'ImmutableProbabilisticTree',\n",
       " 'ImmutableTree',\n",
       " 'IncrementalBottomUpChartParser',\n",
       " 'IncrementalBottomUpLeftCornerChartParser',\n",
       " 'IncrementalChartParser',\n",
       " 'IncrementalLeftCornerChartParser',\n",
       " 'IncrementalTopDownChartParser',\n",
       " 'Index',\n",
       " 'InsideChartParser',\n",
       " 'JSONTaggedDecoder',\n",
       " 'JSONTaggedEncoder',\n",
       " 'KneserNeyProbDist',\n",
       " 'LancasterStemmer',\n",
       " 'LaplaceProbDist',\n",
       " 'LazyConcatenation',\n",
       " 'LazyEnumerate',\n",
       " 'LazyIteratorList',\n",
       " 'LazyMap',\n",
       " 'LazySubsequence',\n",
       " 'LazyZip',\n",
       " 'LeftCornerChartParser',\n",
       " 'LegalitySyllableTokenizer',\n",
       " 'LidstoneProbDist',\n",
       " 'LineTokenizer',\n",
       " 'LogicalExpressionException',\n",
       " 'LongestChartParser',\n",
       " 'MLEProbDist',\n",
       " 'MWETokenizer',\n",
       " 'Mace',\n",
       " 'MaceCommand',\n",
       " 'MaltParser',\n",
       " 'MaxentClassifier',\n",
       " 'Maxent_NE_Chunker',\n",
       " 'Model',\n",
       " 'MultiClassifierI',\n",
       " 'MultiParentedTree',\n",
       " 'MutableProbDist',\n",
       " 'NLTKWordTokenizer',\n",
       " 'NaiveBayesClassifier',\n",
       " 'NaiveBayesDependencyScorer',\n",
       " 'NgramAssocMeasures',\n",
       " 'NgramTagger',\n",
       " 'NonprojectiveDependencyParser',\n",
       " 'Nonterminal',\n",
       " 'OrderedDict',\n",
       " 'PCFG',\n",
       " 'PRETRAINED_TAGGERS',\n",
       " 'Paice',\n",
       " 'ParallelProverBuilder',\n",
       " 'ParallelProverBuilderCommand',\n",
       " 'ParentedTree',\n",
       " 'ParserI',\n",
       " 'PerceptronTagger',\n",
       " 'PhraseTable',\n",
       " 'PorterStemmer',\n",
       " 'PositiveNaiveBayesClassifier',\n",
       " 'ProbDistI',\n",
       " 'ProbabilisticDependencyGrammar',\n",
       " 'ProbabilisticMixIn',\n",
       " 'ProbabilisticNonprojectiveParser',\n",
       " 'ProbabilisticProduction',\n",
       " 'ProbabilisticProjectiveDependencyParser',\n",
       " 'ProbabilisticTree',\n",
       " 'Production',\n",
       " 'ProjectiveDependencyParser',\n",
       " 'Prover9',\n",
       " 'Prover9Command',\n",
       " 'ProxyBasicAuthHandler',\n",
       " 'ProxyDigestAuthHandler',\n",
       " 'ProxyHandler',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'PunktTokenizer',\n",
       " 'QuadgramAssocMeasures',\n",
       " 'QuadgramCollocationFinder',\n",
       " 'RSLPStemmer',\n",
       " 'RTEFeatureExtractor',\n",
       " 'RandomChartParser',\n",
       " 'RangeFeature',\n",
       " 'ReadingCommand',\n",
       " 'RecursiveDescentParser',\n",
       " 'RegexpChunkParser',\n",
       " 'RegexpParser',\n",
       " 'RegexpStemmer',\n",
       " 'RegexpTagger',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'ResolutionProver',\n",
       " 'ResolutionProverCommand',\n",
       " 'SExprTokenizer',\n",
       " 'SLASH',\n",
       " 'Senna',\n",
       " 'SennaChunkTagger',\n",
       " 'SennaNERTagger',\n",
       " 'SennaTagger',\n",
       " 'SequentialBackoffTagger',\n",
       " 'ShiftReduceParser',\n",
       " 'SimpleGoodTuringProbDist',\n",
       " 'SklearnClassifier',\n",
       " 'SlashFeature',\n",
       " 'SnowballStemmer',\n",
       " 'SpaceTokenizer',\n",
       " 'StackDecoder',\n",
       " 'StanfordNERTagger',\n",
       " 'StanfordPOSTagger',\n",
       " 'StanfordSegmenter',\n",
       " 'StanfordTagger',\n",
       " 'StemmerI',\n",
       " 'SteppingChartParser',\n",
       " 'SteppingRecursiveDescentParser',\n",
       " 'SteppingShiftReduceParser',\n",
       " 'SyllableTokenizer',\n",
       " 'TYPE',\n",
       " 'TabTokenizer',\n",
       " 'TableauProver',\n",
       " 'TableauProverCommand',\n",
       " 'TaggerI',\n",
       " 'TestGrammar',\n",
       " 'Text',\n",
       " 'TextCat',\n",
       " 'TextCollection',\n",
       " 'TextTilingTokenizer',\n",
       " 'TnT',\n",
       " 'TokenSearcher',\n",
       " 'ToktokTokenizer',\n",
       " 'TopDownChartParser',\n",
       " 'TransitionParser',\n",
       " 'Tree',\n",
       " 'TreePrettyPrinter',\n",
       " 'TreebankWordDetokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'Trie',\n",
       " 'TrigramAssocMeasures',\n",
       " 'TrigramCollocationFinder',\n",
       " 'TrigramTagger',\n",
       " 'TweetTokenizer',\n",
       " 'TypedMaxentFeatureEncoding',\n",
       " 'Undefined',\n",
       " 'UniformProbDist',\n",
       " 'UnigramTagger',\n",
       " 'UnsortedChartParser',\n",
       " 'Valuation',\n",
       " 'Variable',\n",
       " 'ViterbiParser',\n",
       " 'WekaClassifier',\n",
       " 'WhitespaceTokenizer',\n",
       " 'WittenBellProbDist',\n",
       " 'WordNetLemmatizer',\n",
       " 'WordPunctTokenizer',\n",
       " '__author__',\n",
       " '__author_email__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__classifiers__',\n",
       " '__copyright__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__keywords__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__longdescr__',\n",
       " '__maintainer__',\n",
       " '__maintainer_email__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__url__',\n",
       " '__version__',\n",
       " 'accuracy',\n",
       " 'acyclic_branches_depth_first',\n",
       " 'acyclic_breadth_first',\n",
       " 'acyclic_depth_first',\n",
       " 'acyclic_dic2tree',\n",
       " 'add_logs',\n",
       " 'agreement',\n",
       " 'align',\n",
       " 'alignment_error_rate',\n",
       " 'aline',\n",
       " 'api',\n",
       " 'app',\n",
       " 'apply_features',\n",
       " 'approxrand',\n",
       " 'arity',\n",
       " 'arlstem',\n",
       " 'arlstem2',\n",
       " 'association',\n",
       " 'bigrams',\n",
       " 'binary_distance',\n",
       " 'binary_search_file',\n",
       " 'binding_ops',\n",
       " 'bisect',\n",
       " 'blankline_tokenize',\n",
       " 'bleu',\n",
       " 'bleu_score',\n",
       " 'bllip',\n",
       " 'boolean_ops',\n",
       " 'boxer',\n",
       " 'bracket_parse',\n",
       " 'breadth_first',\n",
       " 'brill',\n",
       " 'brill_trainer',\n",
       " 'build_opener',\n",
       " 'call_megam',\n",
       " 'casual',\n",
       " 'casual_tokenize',\n",
       " 'ccg',\n",
       " 'chain',\n",
       " 'chart',\n",
       " 'chat',\n",
       " 'chomsky_normal_form',\n",
       " 'choose',\n",
       " 'chrf',\n",
       " 'chrf_score',\n",
       " 'chunk',\n",
       " 'cistem',\n",
       " 'classify',\n",
       " 'clause',\n",
       " 'clean_html',\n",
       " 'clean_url',\n",
       " 'cluster',\n",
       " 'collapse_unary',\n",
       " 'collections',\n",
       " 'collocations',\n",
       " 'combinations',\n",
       " 'config_java',\n",
       " 'config_megam',\n",
       " 'config_weka',\n",
       " 'conflicts',\n",
       " 'confusionmatrix',\n",
       " 'conllstr2tree',\n",
       " 'conlltags2tree',\n",
       " 'corenlp',\n",
       " 'corpus',\n",
       " 'crf',\n",
       " 'custom_distance',\n",
       " 'cut_string',\n",
       " 'data',\n",
       " 'decisiontree',\n",
       " 'decorator',\n",
       " 'decorators',\n",
       " 'defaultdict',\n",
       " 'demo',\n",
       " 'dependencygraph',\n",
       " 'deprecated',\n",
       " 'deque',\n",
       " 'destructive',\n",
       " 'discourse',\n",
       " 'distance',\n",
       " 'download',\n",
       " 'download_gui',\n",
       " 'download_shell',\n",
       " 'downloader',\n",
       " 'draw',\n",
       " 'drt',\n",
       " 'earleychart',\n",
       " 'edge_closure',\n",
       " 'edges2dot',\n",
       " 'edit_distance',\n",
       " 'edit_distance_align',\n",
       " 'elementtree_indent',\n",
       " 'entropy',\n",
       " 'equality_preds',\n",
       " 'evaluate',\n",
       " 'evaluate_sents',\n",
       " 'everygrams',\n",
       " 'extract',\n",
       " 'extract_rels',\n",
       " 'extract_test_sentences',\n",
       " 'f_measure',\n",
       " 'featstruct',\n",
       " 'featurechart',\n",
       " 'filestring',\n",
       " 'find',\n",
       " 'flatten',\n",
       " 'fractional_presence',\n",
       " 'functools',\n",
       " 'gale_church',\n",
       " 'gdfa',\n",
       " 'getproxies',\n",
       " 'ghd',\n",
       " 'gleu',\n",
       " 'gleu_score',\n",
       " 'glue',\n",
       " 'grammar',\n",
       " 'grow_diag_final_and',\n",
       " 'guess_encoding',\n",
       " 'help',\n",
       " 'hmm',\n",
       " 'hunpos',\n",
       " 'ibm1',\n",
       " 'ibm2',\n",
       " 'ibm3',\n",
       " 'ibm4',\n",
       " 'ibm5',\n",
       " 'ibm_model',\n",
       " 'ieerstr2tree',\n",
       " 'in_idle',\n",
       " 'induce_pcfg',\n",
       " 'inference',\n",
       " 'infile',\n",
       " 'inspect',\n",
       " 'install_opener',\n",
       " 'internals',\n",
       " 'interpret_sents',\n",
       " 'interval_distance',\n",
       " 'invert_dict',\n",
       " 'invert_graph',\n",
       " 'is_rel',\n",
       " 'islice',\n",
       " 'isri',\n",
       " 'jaccard_distance',\n",
       " 'json_tags',\n",
       " 'jsontags',\n",
       " 'lancaster',\n",
       " 'lazyimport',\n",
       " 'legality_principle',\n",
       " 'lfg',\n",
       " 'line_tokenize',\n",
       " 'linearlogic',\n",
       " 'lm',\n",
       " 'load',\n",
       " 'load_parser',\n",
       " 'locale',\n",
       " 'log_likelihood',\n",
       " 'logic',\n",
       " 'mace',\n",
       " 'malt',\n",
       " 'map_tag',\n",
       " 'mapping',\n",
       " 'masi_distance',\n",
       " 'maxent',\n",
       " 'megam',\n",
       " 'memoize',\n",
       " 'meteor',\n",
       " 'meteor_score',\n",
       " 'metrics',\n",
       " 'misc',\n",
       " 'mwe',\n",
       " 'naivebayes',\n",
       " 'named_entity',\n",
       " 'ne_chunk',\n",
       " 'ne_chunk_sents',\n",
       " 'ne_chunker',\n",
       " 'ngrams',\n",
       " 'nist',\n",
       " 'nist_score',\n",
       " 'nonprojectivedependencyparser',\n",
       " 'nonterminals',\n",
       " 'numpy',\n",
       " 'os',\n",
       " 'pad_sequence',\n",
       " 'paice',\n",
       " 'pairwise',\n",
       " 'parallelize_preprocess',\n",
       " 'parse',\n",
       " 'parse_sents',\n",
       " 'pchart',\n",
       " 'perceptron',\n",
       " 'phrase_based',\n",
       " 'pk',\n",
       " 'porter',\n",
       " 'pos_tag',\n",
       " 'pos_tag_sents',\n",
       " 'positivenaivebayes',\n",
       " 'pprint',\n",
       " 'pr',\n",
       " 'precision',\n",
       " 'presence',\n",
       " 'print_string',\n",
       " 'probability',\n",
       " 'projectivedependencyparser',\n",
       " 'prover9',\n",
       " 'punkt',\n",
       " 'pydoc',\n",
       " 'raise_unorderable_types',\n",
       " 'ranks_from_scores',\n",
       " 'ranks_from_sequence',\n",
       " 're',\n",
       " 're_show',\n",
       " 'read_grammar',\n",
       " 'read_logic',\n",
       " 'read_valuation',\n",
       " 'recall',\n",
       " 'recursivedescent',\n",
       " 'regexp',\n",
       " 'regexp_span_tokenize',\n",
       " 'regexp_tokenize',\n",
       " 'register_tag',\n",
       " 'relextract',\n",
       " 'repp',\n",
       " 'resolution',\n",
       " 'ribes',\n",
       " 'ribes_score',\n",
       " 'root_semrep',\n",
       " 'rslp',\n",
       " 'rte_classifier',\n",
       " 'rte_classify',\n",
       " 'rte_features',\n",
       " 'rtuple',\n",
       " 'scikitlearn',\n",
       " 'scores',\n",
       " 'segmentation',\n",
       " 'sem',\n",
       " 'senna',\n",
       " 'sent_tokenize',\n",
       " 'sequential',\n",
       " 'set2rel',\n",
       " 'set_proxy',\n",
       " 'sexpr',\n",
       " 'sexpr_tokenize',\n",
       " 'shiftreduce',\n",
       " 'simple',\n",
       " 'sinica_parse',\n",
       " 'skipgrams',\n",
       " 'skolemize',\n",
       " 'slice_bounds',\n",
       " 'snowball',\n",
       " 'sonority_sequencing',\n",
       " 'spearman',\n",
       " 'spearman_correlation',\n",
       " 'stack_decoder',\n",
       " 'stanford',\n",
       " 'stanford_segmenter',\n",
       " 'stem',\n",
       " 'str2tuple',\n",
       " 'string_span_tokenize',\n",
       " 'subprocess',\n",
       " 'subsumes',\n",
       " 'sum_logs',\n",
       " 'tabdata',\n",
       " 'tableau',\n",
       " 'tadm',\n",
       " 'tag',\n",
       " 'tagset_mapping',\n",
       " 'tagstr2tree',\n",
       " 'tbl',\n",
       " 'tee',\n",
       " 'text',\n",
       " 'textcat',\n",
       " 'texttiling',\n",
       " 'textwrap',\n",
       " 'tkinter',\n",
       " 'tnt',\n",
       " 'tokenize',\n",
       " 'tokenwrap',\n",
       " 'toktok',\n",
       " 'toolbox',\n",
       " 'total_ordering',\n",
       " 'trace',\n",
       " 'transitionparser',\n",
       " 'transitive_closure',\n",
       " 'translate',\n",
       " 'tree',\n",
       " 'tree2conllstr',\n",
       " 'tree2conlltags',\n",
       " 'treebank',\n",
       " 'trigrams',\n",
       " 'tuple2str',\n",
       " 'un_chomsky_normal_form',\n",
       " 'unicodedata',\n",
       " 'unify',\n",
       " 'unique_list',\n",
       " 'untag',\n",
       " 'unweighted_minimum_spanning_dict',\n",
       " 'unweighted_minimum_spanning_digraph',\n",
       " 'unweighted_minimum_spanning_tree',\n",
       " 'usage',\n",
       " 'util',\n",
       " 'version_file',\n",
       " 'viterbi',\n",
       " 'warnings',\n",
       " 'weka',\n",
       " 'windowdiff',\n",
       " 'word_tokenize',\n",
       " 'wordnet',\n",
       " 'wordpunct_tokenize',\n",
       " 'wsd']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea2cde55-cdf8-4341-bc83-78407e3bf867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2a0088d-1223-473d-87d2-e05f3e5abe9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_LazyModule__lazymodule_globals',\n",
       " '_LazyModule__lazymodule_import',\n",
       " '_LazyModule__lazymodule_init',\n",
       " '_LazyModule__lazymodule_loaded',\n",
       " '_LazyModule__lazymodule_locals',\n",
       " '_LazyModule__lazymodule_name',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk.corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba379341-f0ef-41e9-8bef-3c2321a05e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.text import Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6399e905-d809-4c35-96f2-06856b41e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"\"\"Natural language is a complex system used to express meanings. In this system, words are the basic unit of the meaning. As the name implies, word vectors are vectors used to represent words, and can also be considered as feature vectors or representations of words. The technique of mapping words to real vectors is called word embedding. In recent years, word embedding has gradually become the basic knowledge of natural language processing.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3518dfdf-d03d-4f7a-bdad-c6b38d68eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language is a complex system used to express meanings. In this system, words are the basic unit of the meaning. As the name implies, word vectors are vectors used to represent words, and can also be considered as feature vectors or representations of words. The technique of mapping words to real vectors is called word embedding. In recent years, word embedding has gradually become the basic knowledge of natural language processing.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04bf5d-6d88-44f7-9bd3-3a72cc03a6fb",
   "metadata": {},
   "source": [
    "# split token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1607c316-cd8e-4b39-b240-de079cb93634",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741ed495-3411-4d5f-acaf-a7de5e743b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [i.lower() for i in  tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01cc2ec4-f63a-4041-8b34-c16997fdefee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural',\n",
       " 'language',\n",
       " 'is',\n",
       " 'a',\n",
       " 'complex',\n",
       " 'system',\n",
       " 'used',\n",
       " 'to',\n",
       " 'express',\n",
       " 'meanings',\n",
       " '.',\n",
       " 'in',\n",
       " 'this',\n",
       " 'system',\n",
       " ',',\n",
       " 'words',\n",
       " 'are',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'meaning',\n",
       " '.',\n",
       " 'as',\n",
       " 'the',\n",
       " 'name',\n",
       " 'implies',\n",
       " ',',\n",
       " 'word',\n",
       " 'vectors',\n",
       " 'are',\n",
       " 'vectors',\n",
       " 'used',\n",
       " 'to',\n",
       " 'represent',\n",
       " 'words',\n",
       " ',',\n",
       " 'and',\n",
       " 'can',\n",
       " 'also',\n",
       " 'be',\n",
       " 'considered',\n",
       " 'as',\n",
       " 'feature',\n",
       " 'vectors',\n",
       " 'or',\n",
       " 'representations',\n",
       " 'of',\n",
       " 'words',\n",
       " '.',\n",
       " 'the',\n",
       " 'technique',\n",
       " 'of',\n",
       " 'mapping',\n",
       " 'words',\n",
       " 'to',\n",
       " 'real',\n",
       " 'vectors',\n",
       " 'is',\n",
       " 'called',\n",
       " 'word',\n",
       " 'embedding',\n",
       " '.',\n",
       " 'in',\n",
       " 'recent',\n",
       " 'years',\n",
       " ',',\n",
       " 'word',\n",
       " 'embedding',\n",
       " 'has',\n",
       " 'gradually',\n",
       " 'become',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e88470a5-8ff9-4899-8e35-fdc9a93bcdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 72)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(input_str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9e24f-3762-4dbc-947b-d02d64169d2e",
   "metadata": {},
   "source": [
    "# Create Text Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53796a32-82ad-4b1c-952e-b137f4093b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module nltk.text in nltk:\n",
      "\n",
      "NAME\n",
      "    nltk.text\n",
      "\n",
      "DESCRIPTION\n",
      "    This module brings together a variety of NLTK functionality for\n",
      "    text analysis, and provides simple, interactive interfaces.\n",
      "    Functionality includes: concordancing, collocation discovery,\n",
      "    regular expression search over tokenized strings, and\n",
      "    distributional similarity.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        ConcordanceIndex\n",
      "        ContextIndex\n",
      "        Text\n",
      "            TextCollection\n",
      "        TokenSearcher\n",
      "    \n",
      "    class ConcordanceIndex(builtins.object)\n",
      "     |  ConcordanceIndex(tokens, key=<function ConcordanceIndex.<lambda> at 0x7f525e7010d0>)\n",
      "     |  \n",
      "     |  An index that can be used to look up the offset locations at which\n",
      "     |  a given word occurs in a document.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, tokens, key=<function ConcordanceIndex.<lambda> at 0x7f525e7010d0>)\n",
      "     |      Construct a new concordance index.\n",
      "     |      \n",
      "     |      :param tokens: The document (list of tokens) that this\n",
      "     |          concordance index was created from.  This list can be used\n",
      "     |          to access the context of a given word occurrence.\n",
      "     |      :param key: A function that maps each token to a normalized\n",
      "     |          version that will be used as a key in the index.  E.g., if\n",
      "     |          you use ``key=lambda s:s.lower()``, then the index will be\n",
      "     |          case-insensitive.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  find_concordance(self, word, width=80)\n",
      "     |      Find all concordance lines given the query word.\n",
      "     |      \n",
      "     |      Provided with a list of words, these will be found as a phrase.\n",
      "     |  \n",
      "     |  offsets(self, word)\n",
      "     |      :rtype: list(int)\n",
      "     |      :return: A list of the offset positions at which the given\n",
      "     |          word occurs.  If a key function was specified for the\n",
      "     |          index, then given word's key will be looked up.\n",
      "     |  \n",
      "     |  print_concordance(self, word, width=80, lines=25)\n",
      "     |      Print concordance lines given the query word.\n",
      "     |      :param word: The target word or phrase (a list of strings)\n",
      "     |      :type word: str or list\n",
      "     |      :param lines: The number of lines to display (default=25)\n",
      "     |      :type lines: int\n",
      "     |      :param width: The width of each line, in characters (default=80)\n",
      "     |      :type width: int\n",
      "     |      :param save: The option to save the concordance.\n",
      "     |      :type save: bool\n",
      "     |  \n",
      "     |  tokens(self)\n",
      "     |      :rtype: list(str)\n",
      "     |      :return: The document that this concordance index was\n",
      "     |          created from.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ContextIndex(builtins.object)\n",
      "     |  ContextIndex(tokens, context_func=None, filter=None, key=<function ContextIndex.<lambda> at 0x7f525e6f9d30>)\n",
      "     |  \n",
      "     |  A bidirectional index between words and their 'contexts' in a text.\n",
      "     |  The context of a word is usually defined to be the words that occur\n",
      "     |  in a fixed window around the word; but other definitions may also\n",
      "     |  be used by providing a custom context function.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, tokens, context_func=None, filter=None, key=<function ContextIndex.<lambda> at 0x7f525e6f9d30>)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  common_contexts(self, words, fail_on_unknown=False)\n",
      "     |      Find contexts where the specified words can all appear; and\n",
      "     |      return a frequency distribution mapping each context to the\n",
      "     |      number of times that context was used.\n",
      "     |      \n",
      "     |      :param words: The words used to seed the similarity search\n",
      "     |      :type words: str\n",
      "     |      :param fail_on_unknown: If true, then raise a value error if\n",
      "     |          any of the given words do not occur at all in the index.\n",
      "     |  \n",
      "     |  similar_words(self, word, n=20)\n",
      "     |  \n",
      "     |  tokens(self)\n",
      "     |      :rtype: list(str)\n",
      "     |      :return: The document that this context index was\n",
      "     |          created from.\n",
      "     |  \n",
      "     |  word_similarity_dict(self, word)\n",
      "     |      Return a dictionary mapping from words to 'similarity scores,'\n",
      "     |      indicating how often these two words occur in the same\n",
      "     |      context.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Text(builtins.object)\n",
      "     |  Text(tokens, name=None)\n",
      "     |  \n",
      "     |  A wrapper around a sequence of simple (string) tokens, which is\n",
      "     |  intended to support initial exploration of texts (via the\n",
      "     |  interactive console).  Its methods perform a variety of analyses\n",
      "     |  on the text's contexts (e.g., counting, concordancing, collocation\n",
      "     |  discovery), and display the results.  If you wish to write a\n",
      "     |  program which makes use of these analyses, then you should bypass\n",
      "     |  the ``Text`` class, and use the appropriate analysis function or\n",
      "     |  class directly instead.\n",
      "     |  \n",
      "     |  A ``Text`` is typically initialized from a given document or\n",
      "     |  corpus.  E.g.:\n",
      "     |  \n",
      "     |  >>> import nltk.corpus\n",
      "     |  >>> from nltk.text import Text\n",
      "     |  >>> moby = Text(nltk.corpus.gutenberg.words('melville-moby_dick.txt'))\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |  \n",
      "     |  __init__(self, tokens, name=None)\n",
      "     |      Create a Text object.\n",
      "     |      \n",
      "     |      :param tokens: The source text.\n",
      "     |      :type tokens: sequence of str\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  collocation_list(self, num=20, window_size=2)\n",
      "     |      Return collocations derived from the text, ignoring stopwords.\n",
      "     |      \n",
      "     |          >>> from nltk.book import text4\n",
      "     |          >>> text4.collocation_list()[:2]\n",
      "     |          [('United', 'States'), ('fellow', 'citizens')]\n",
      "     |      \n",
      "     |      :param num: The maximum number of collocations to return.\n",
      "     |      :type num: int\n",
      "     |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
      "     |      :type window_size: int\n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  collocations(self, num=20, window_size=2)\n",
      "     |      Print collocations derived from the text, ignoring stopwords.\n",
      "     |      \n",
      "     |          >>> from nltk.book import text4\n",
      "     |          >>> text4.collocations() # doctest: +NORMALIZE_WHITESPACE\n",
      "     |          United States; fellow citizens; years ago; four years; Federal\n",
      "     |          Government; General Government; American people; Vice President; God\n",
      "     |          bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "     |          Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "     |          tribes; public debt; foreign nations\n",
      "     |      \n",
      "     |      \n",
      "     |      :param num: The maximum number of collocations to print.\n",
      "     |      :type num: int\n",
      "     |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
      "     |      :type window_size: int\n",
      "     |  \n",
      "     |  common_contexts(self, words, num=20)\n",
      "     |      Find contexts where the specified words appear; list\n",
      "     |      most frequent common contexts first.\n",
      "     |      \n",
      "     |      :param words: The words used to seed the similarity search\n",
      "     |      :type words: str\n",
      "     |      :param num: The number of words to generate (default=20)\n",
      "     |      :type num: int\n",
      "     |      :seealso: ContextIndex.common_contexts()\n",
      "     |  \n",
      "     |  concordance(self, word, width=79, lines=25)\n",
      "     |      Prints a concordance for ``word`` with the specified context window.\n",
      "     |      Word matching is not case-sensitive.\n",
      "     |      \n",
      "     |      :param word: The target word or phrase (a list of strings)\n",
      "     |      :type word: str or list\n",
      "     |      :param width: The width of each line, in characters (default=80)\n",
      "     |      :type width: int\n",
      "     |      :param lines: The number of lines to display (default=25)\n",
      "     |      :type lines: int\n",
      "     |      \n",
      "     |      :seealso: ``ConcordanceIndex``\n",
      "     |  \n",
      "     |  concordance_list(self, word, width=79, lines=25)\n",
      "     |      Generate a concordance for ``word`` with the specified context window.\n",
      "     |      Word matching is not case-sensitive.\n",
      "     |      \n",
      "     |      :param word: The target word or phrase (a list of strings)\n",
      "     |      :type word: str or list\n",
      "     |      :param width: The width of each line, in characters (default=80)\n",
      "     |      :type width: int\n",
      "     |      :param lines: The number of lines to display (default=25)\n",
      "     |      :type lines: int\n",
      "     |      \n",
      "     |      :seealso: ``ConcordanceIndex``\n",
      "     |  \n",
      "     |  count(self, word)\n",
      "     |      Count the number of times this word appears in the text.\n",
      "     |  \n",
      "     |  dispersion_plot(self, words)\n",
      "     |      Produce a plot showing the distribution of the words through the text.\n",
      "     |      Requires pylab to be installed.\n",
      "     |      \n",
      "     |      :param words: The words to be plotted\n",
      "     |      :type words: list(str)\n",
      "     |      :seealso: nltk.draw.dispersion_plot()\n",
      "     |  \n",
      "     |  findall(self, regexp)\n",
      "     |      Find instances of the regular expression in the text.\n",
      "     |      The text is a list of tokens, and a regexp pattern to match\n",
      "     |      a single token must be surrounded by angle brackets.  E.g.\n",
      "     |      \n",
      "     |      >>> from nltk.book import text1, text5, text9\n",
      "     |      >>> text5.findall(\"<.*><.*><bro>\")\n",
      "     |      you rule bro; telling you bro; u twizted bro\n",
      "     |      >>> text1.findall(\"<a>(<.*>)<man>\")\n",
      "     |      monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "     |      mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "     |      pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "     |      brave; brave; brave\n",
      "     |      >>> text9.findall(\"<th.*>{3,}\")\n",
      "     |      thread through those; the thought that; that the thing; the thing\n",
      "     |      that; that that thing; through these than through; them that the;\n",
      "     |      through the thick; them that they; thought that the\n",
      "     |      \n",
      "     |      :param regexp: A regular expression\n",
      "     |      :type regexp: str\n",
      "     |  \n",
      "     |  generate(self, length=100, text_seed=None, random_seed=42)\n",
      "     |      Print random text, generated using a trigram language model.\n",
      "     |      See also `help(nltk.lm)`.\n",
      "     |      \n",
      "     |      :param length: The length of text to generate (default=100)\n",
      "     |      :type length: int\n",
      "     |      \n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :type text_seed: list(str)\n",
      "     |      \n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |          makes the random sampling part of generation reproducible. (default=42)\n",
      "     |      :type random_seed: int\n",
      "     |  \n",
      "     |  index(self, word)\n",
      "     |      Find the index of the first occurrence of the word in the text.\n",
      "     |  \n",
      "     |  plot(self, *args)\n",
      "     |      See documentation for FreqDist.plot()\n",
      "     |      :seealso: nltk.prob.FreqDist.plot()\n",
      "     |  \n",
      "     |  readability(self, method)\n",
      "     |  \n",
      "     |  similar(self, word, num=20)\n",
      "     |      Distributional similarity: find other words which appear in the\n",
      "     |      same contexts as the specified word; list most similar words first.\n",
      "     |      \n",
      "     |      :param word: The word used to seed the similarity search\n",
      "     |      :type word: str\n",
      "     |      :param num: The number of words to generate (default=20)\n",
      "     |      :type num: int\n",
      "     |      :seealso: ContextIndex.similar_words()\n",
      "     |  \n",
      "     |  vocab(self)\n",
      "     |      :seealso: nltk.prob.FreqDist\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TextCollection(Text)\n",
      "     |  TextCollection(source)\n",
      "     |  \n",
      "     |  A collection of texts, which can be loaded with list of texts, or\n",
      "     |  with a corpus consisting of one or more texts, and which supports\n",
      "     |  counting, concordancing, collocation discovery, etc.  Initialize a\n",
      "     |  TextCollection as follows:\n",
      "     |  \n",
      "     |  >>> import nltk.corpus\n",
      "     |  >>> from nltk.text import TextCollection\n",
      "     |  >>> from nltk.book import text1, text2, text3\n",
      "     |  >>> gutenberg = TextCollection(nltk.corpus.gutenberg)\n",
      "     |  >>> mytexts = TextCollection([text1, text2, text3])\n",
      "     |  \n",
      "     |  Iterating over a TextCollection produces all the tokens of all the\n",
      "     |  texts in order.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TextCollection\n",
      "     |      Text\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, source)\n",
      "     |      Create a Text object.\n",
      "     |      \n",
      "     |      :param tokens: The source text.\n",
      "     |      :type tokens: sequence of str\n",
      "     |  \n",
      "     |  idf(self, term)\n",
      "     |      The number of texts in the corpus divided by the\n",
      "     |      number of texts that the term appears in.\n",
      "     |      If a term does not appear in the corpus, 0.0 is returned.\n",
      "     |  \n",
      "     |  tf(self, term, text)\n",
      "     |      The frequency of the term in text.\n",
      "     |  \n",
      "     |  tf_idf(self, term, text)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Text:\n",
      "     |  \n",
      "     |  __getitem__(self, i)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  collocation_list(self, num=20, window_size=2)\n",
      "     |      Return collocations derived from the text, ignoring stopwords.\n",
      "     |      \n",
      "     |          >>> from nltk.book import text4\n",
      "     |          >>> text4.collocation_list()[:2]\n",
      "     |          [('United', 'States'), ('fellow', 'citizens')]\n",
      "     |      \n",
      "     |      :param num: The maximum number of collocations to return.\n",
      "     |      :type num: int\n",
      "     |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
      "     |      :type window_size: int\n",
      "     |      :rtype: list(tuple(str, str))\n",
      "     |  \n",
      "     |  collocations(self, num=20, window_size=2)\n",
      "     |      Print collocations derived from the text, ignoring stopwords.\n",
      "     |      \n",
      "     |          >>> from nltk.book import text4\n",
      "     |          >>> text4.collocations() # doctest: +NORMALIZE_WHITESPACE\n",
      "     |          United States; fellow citizens; years ago; four years; Federal\n",
      "     |          Government; General Government; American people; Vice President; God\n",
      "     |          bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "     |          Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "     |          tribes; public debt; foreign nations\n",
      "     |      \n",
      "     |      \n",
      "     |      :param num: The maximum number of collocations to print.\n",
      "     |      :type num: int\n",
      "     |      :param window_size: The number of tokens spanned by a collocation (default=2)\n",
      "     |      :type window_size: int\n",
      "     |  \n",
      "     |  common_contexts(self, words, num=20)\n",
      "     |      Find contexts where the specified words appear; list\n",
      "     |      most frequent common contexts first.\n",
      "     |      \n",
      "     |      :param words: The words used to seed the similarity search\n",
      "     |      :type words: str\n",
      "     |      :param num: The number of words to generate (default=20)\n",
      "     |      :type num: int\n",
      "     |      :seealso: ContextIndex.common_contexts()\n",
      "     |  \n",
      "     |  concordance(self, word, width=79, lines=25)\n",
      "     |      Prints a concordance for ``word`` with the specified context window.\n",
      "     |      Word matching is not case-sensitive.\n",
      "     |      \n",
      "     |      :param word: The target word or phrase (a list of strings)\n",
      "     |      :type word: str or list\n",
      "     |      :param width: The width of each line, in characters (default=80)\n",
      "     |      :type width: int\n",
      "     |      :param lines: The number of lines to display (default=25)\n",
      "     |      :type lines: int\n",
      "     |      \n",
      "     |      :seealso: ``ConcordanceIndex``\n",
      "     |  \n",
      "     |  concordance_list(self, word, width=79, lines=25)\n",
      "     |      Generate a concordance for ``word`` with the specified context window.\n",
      "     |      Word matching is not case-sensitive.\n",
      "     |      \n",
      "     |      :param word: The target word or phrase (a list of strings)\n",
      "     |      :type word: str or list\n",
      "     |      :param width: The width of each line, in characters (default=80)\n",
      "     |      :type width: int\n",
      "     |      :param lines: The number of lines to display (default=25)\n",
      "     |      :type lines: int\n",
      "     |      \n",
      "     |      :seealso: ``ConcordanceIndex``\n",
      "     |  \n",
      "     |  count(self, word)\n",
      "     |      Count the number of times this word appears in the text.\n",
      "     |  \n",
      "     |  dispersion_plot(self, words)\n",
      "     |      Produce a plot showing the distribution of the words through the text.\n",
      "     |      Requires pylab to be installed.\n",
      "     |      \n",
      "     |      :param words: The words to be plotted\n",
      "     |      :type words: list(str)\n",
      "     |      :seealso: nltk.draw.dispersion_plot()\n",
      "     |  \n",
      "     |  findall(self, regexp)\n",
      "     |      Find instances of the regular expression in the text.\n",
      "     |      The text is a list of tokens, and a regexp pattern to match\n",
      "     |      a single token must be surrounded by angle brackets.  E.g.\n",
      "     |      \n",
      "     |      >>> from nltk.book import text1, text5, text9\n",
      "     |      >>> text5.findall(\"<.*><.*><bro>\")\n",
      "     |      you rule bro; telling you bro; u twizted bro\n",
      "     |      >>> text1.findall(\"<a>(<.*>)<man>\")\n",
      "     |      monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "     |      mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "     |      pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "     |      brave; brave; brave\n",
      "     |      >>> text9.findall(\"<th.*>{3,}\")\n",
      "     |      thread through those; the thought that; that the thing; the thing\n",
      "     |      that; that that thing; through these than through; them that the;\n",
      "     |      through the thick; them that they; thought that the\n",
      "     |      \n",
      "     |      :param regexp: A regular expression\n",
      "     |      :type regexp: str\n",
      "     |  \n",
      "     |  generate(self, length=100, text_seed=None, random_seed=42)\n",
      "     |      Print random text, generated using a trigram language model.\n",
      "     |      See also `help(nltk.lm)`.\n",
      "     |      \n",
      "     |      :param length: The length of text to generate (default=100)\n",
      "     |      :type length: int\n",
      "     |      \n",
      "     |      :param text_seed: Generation can be conditioned on preceding context.\n",
      "     |      :type text_seed: list(str)\n",
      "     |      \n",
      "     |      :param random_seed: A random seed or an instance of `random.Random`. If provided,\n",
      "     |          makes the random sampling part of generation reproducible. (default=42)\n",
      "     |      :type random_seed: int\n",
      "     |  \n",
      "     |  index(self, word)\n",
      "     |      Find the index of the first occurrence of the word in the text.\n",
      "     |  \n",
      "     |  plot(self, *args)\n",
      "     |      See documentation for FreqDist.plot()\n",
      "     |      :seealso: nltk.prob.FreqDist.plot()\n",
      "     |  \n",
      "     |  readability(self, method)\n",
      "     |  \n",
      "     |  similar(self, word, num=20)\n",
      "     |      Distributional similarity: find other words which appear in the\n",
      "     |      same contexts as the specified word; list most similar words first.\n",
      "     |      \n",
      "     |      :param word: The word used to seed the similarity search\n",
      "     |      :type word: str\n",
      "     |      :param num: The number of words to generate (default=20)\n",
      "     |      :type num: int\n",
      "     |      :seealso: ContextIndex.similar_words()\n",
      "     |  \n",
      "     |  vocab(self)\n",
      "     |      :seealso: nltk.prob.FreqDist\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Text:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TokenSearcher(builtins.object)\n",
      "     |  TokenSearcher(tokens)\n",
      "     |  \n",
      "     |  A class that makes it easier to use regular expressions to search\n",
      "     |  over tokenized strings.  The tokenized string is converted to a\n",
      "     |  string where tokens are marked with angle brackets -- e.g.,\n",
      "     |  ``'<the><window><is><still><open>'``.  The regular expression\n",
      "     |  passed to the ``findall()`` method is modified to treat angle\n",
      "     |  brackets as non-capturing parentheses, in addition to matching the\n",
      "     |  token boundaries; and to have ``'.'`` not match the angle brackets.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, tokens)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  findall(self, regexp)\n",
      "     |      Find instances of the regular expression in the text.\n",
      "     |      The text is a list of tokens, and a regexp pattern to match\n",
      "     |      a single token must be surrounded by angle brackets.  E.g.\n",
      "     |      \n",
      "     |      >>> from nltk.text import TokenSearcher\n",
      "     |      >>> from nltk.book import text1, text5, text9\n",
      "     |      >>> text5.findall(\"<.*><.*><bro>\")\n",
      "     |      you rule bro; telling you bro; u twizted bro\n",
      "     |      >>> text1.findall(\"<a>(<.*>)<man>\")\n",
      "     |      monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "     |      mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "     |      pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "     |      brave; brave; brave\n",
      "     |      >>> text9.findall(\"<th.*>{3,}\")\n",
      "     |      thread through those; the thought that; that the thing; the thing\n",
      "     |      that; that that thing; through these than through; them that the;\n",
      "     |      through the thick; them that they; thought that the\n",
      "     |      \n",
      "     |      :param regexp: A regular expression\n",
      "     |      :type regexp: str\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['ContextIndex', 'ConcordanceIndex', 'TokenSearcher', 'Text'...\n",
      "\n",
      "FILE\n",
      "    /home/ljj/data/anaconda3/envs/nlptest/lib/python3.9/site-packages/nltk/text.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "effd96c5-38ab-42a2-951a-cc3c60c2f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef324766-d24a-442a-9d8c-8ba2675f6b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.count(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5360c146-dfed-4f10-82dd-0540493fb21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b138447-f672-4103-8ece-7f3318f625a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Samples', ylabel='Counts'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502a9f0-c483-49dd-a5ca-a0648f3234c9",
   "metadata": {},
   "source": [
    "# stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3e84f78-3135-43a6-aa4c-50315160b03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63601e35-adc9-43b2-80d8-a89362a05d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopwords Corpus  This corpus contains lists of stop words for several languages.  These are high-frequency grammatical words which are usually ignored in text retrieval applications.  They were obtained from: http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/  The stop words for the Romanian language were obtained from: http://arlc.ro/resources/  The English list has been augmented https://github.com/nltk/nltk_data/issues/22  The German list has been corrected https://github.com/nltk/nltk_data/pull/49  A Kazakh list has been added https://github.com/nltk/nltk_data/pull/52  A Nepali list has been added https://github.com/nltk/nltk_data/pull/83  An Azerbaijani list has been added https://github.com/nltk/nltk_data/pull/100  A Greek list has been added https://github.com/nltk/nltk_data/pull/103  An Indonesian list has been added https://github.com/nltk/nltk_data/pull/112 '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.readme().replace('\\n', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cbb548c-7145-4158-9344-6391355f4f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_citation',\n",
       " '_encoding',\n",
       " '_fileids',\n",
       " '_get_root',\n",
       " '_license',\n",
       " '_readme',\n",
       " '_root',\n",
       " '_tagset',\n",
       " '_unload',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'citation',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'license',\n",
       " 'open',\n",
       " 'raw',\n",
       " 'readme',\n",
       " 'root',\n",
       " 'words']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3370522a-4fdc-4dbd-b94e-991c643da27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2f8d910-d402-4582-8485-282e8da1eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw(\"english\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31cb093e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad47f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = [i.lower() for i in tokens]\n",
    "test_words_set = set(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9187e0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'and',\n",
       " 'are',\n",
       " 'as',\n",
       " 'be',\n",
       " 'can',\n",
       " 'has',\n",
       " 'in',\n",
       " 'is',\n",
       " 'of',\n",
       " 'or',\n",
       " 'the',\n",
       " 'this',\n",
       " 'to'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words_set.intersection(set(stopwords.words(\"english\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990725e",
   "metadata": {},
   "source": [
    "# filter stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "545d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_text_words = list(filter(lambda a: a not in stopwords.words(\"english\"), test_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "257b2bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['become',\n",
       " 'representations',\n",
       " 'recent',\n",
       " 'words',\n",
       " 'represent',\n",
       " 'meanings',\n",
       " 'unit',\n",
       " 'used',\n",
       " 'name',\n",
       " 'feature',\n",
       " 'embedding',\n",
       " 'processing',\n",
       " 'implies',\n",
       " 'mapping',\n",
       " 'system',\n",
       " 'natural',\n",
       " 'considered',\n",
       " 'years',\n",
       " 'called',\n",
       " 'knowledge',\n",
       " 'complex',\n",
       " 'word',\n",
       " 'technique',\n",
       " 'gradually',\n",
       " 'language',\n",
       " 'also',\n",
       " 'vectors',\n",
       " 'real',\n",
       " '.',\n",
       " ',',\n",
       " 'express',\n",
       " 'meaning',\n",
       " 'basic']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09982f",
   "metadata": {},
   "source": [
    "# word tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b76156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/ljj/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"averaged_perceptron_tagger_eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a64448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b01b4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pos_tag in module nltk.tag:\n",
      "\n",
      "pos_tag(tokens, tagset=None, lang='eng')\n",
      "    Use NLTK's currently recommended part of speech tagger to\n",
      "    tag the given list of tokens.\n",
      "    \n",
      "        >>> from nltk.tag import pos_tag\n",
      "        >>> from nltk.tokenize import word_tokenize\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\")) # doctest: +NORMALIZE_WHITESPACE\n",
      "        [('John', 'NNP'), (\"'s\", 'POS'), ('big', 'JJ'), ('idea', 'NN'), ('is', 'VBZ'),\n",
      "        (\"n't\", 'RB'), ('all', 'PDT'), ('that', 'DT'), ('bad', 'JJ'), ('.', '.')]\n",
      "        >>> pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"), tagset='universal') # doctest: +NORMALIZE_WHITESPACE\n",
      "        [('John', 'NOUN'), (\"'s\", 'PRT'), ('big', 'ADJ'), ('idea', 'NOUN'), ('is', 'VERB'),\n",
      "        (\"n't\", 'ADV'), ('all', 'DET'), ('that', 'DET'), ('bad', 'ADJ'), ('.', '.')]\n",
      "    \n",
      "    NB. Use `pos_tag_sents()` for efficient tagging of more than one sentence.\n",
      "    \n",
      "    :param tokens: Sequence of tokens to be tagged\n",
      "    :type tokens: list(str)\n",
      "    :param tagset: the tagset to be used, e.g. universal, wsj, brown\n",
      "    :type tagset: str\n",
      "    :param lang: the ISO 639 code of the language, e.g. 'eng' for English, 'rus' for Russian\n",
      "    :type lang: str\n",
      "    :return: The tagged tokens\n",
      "    :rtype: list(tuple(str, str))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359e0e0",
   "metadata": {},
   "source": [
    "- **CC**:     coordinatingconjunction \n",
    "- **CD**:     cardinaldigit    \n",
    "- **DT**:     determiner   thesomemy \n",
    "- **EX**:     existentialthere (like:\"there is\"... think of it like \"thereexists\")   \n",
    "- **FW**:     foreignword  \n",
    "- **IN**:     preposition/subordinating conjunction/\n",
    "- **JJ**:     adjective    'big'  \n",
    "- **JJR**:    adjective, comparative 'bigger' \n",
    "- **JJS**:    adjective, superlative 'biggest'  \n",
    "- **LS**:     listmarker  1)\n",
    "- **MD**:     modal (could, will)  , \n",
    "- **NN**:     noun, singular 'desk' \n",
    "- **NNS**:    nounplural  'desks'  \n",
    "- **NNP**:    propernoun, singular     'Harrison' \n",
    "- **NNPS**:  proper noun, plural 'Americans'  \n",
    "- **PDT**:    predeterminer      'all the kids'  \n",
    "- **POS**:    possessiveending  parent's     \n",
    "- **PRP**:    personalpronoun   I, he, she  \n",
    "- **PRP$**:  possessive pronoun my, his, hers  \n",
    "- **RB**:     adverb very, silently,       \n",
    "- **RBR**:    adverb,comparative better   \n",
    "- **RBS**:    adverb,superlative best    \n",
    "- **RP**:     particle     give up ()\n",
    "- **TO**:     to    go 'to' the store.\n",
    "- **UH**:     interjection errrrrrrrm  \n",
    "- **VB**:     verb, baseform    take   \n",
    "- **VBD**:    verb, pasttense   took      \n",
    "- **VBG**:    verb,gerund/present participle taking   /\n",
    "- **VBN**:    verb, pastparticiple     taken   \n",
    "- **VBP**:    verb,sing. present, non-3d     take   \n",
    "- **VBZ**:    verb, 3rdperson sing. present  takes     \n",
    "- **WDT**:    wh-determiner      which  thesomemy \n",
    "- **WP**:     wh-pronoun   who, what \n",
    "- **WP$**:    possessivewh-pronoun     whose  \n",
    "- **WRB**:    wh-abverb    where, when "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65a8699b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('complex', 'JJ'),\n",
       " ('system', 'NN'),\n",
       " ('used', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('express', 'VB'),\n",
       " ('meanings', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('system', 'NN'),\n",
       " (',', ','),\n",
       " ('words', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('basic', 'JJ'),\n",
       " ('unit', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('meaning', 'NN'),\n",
       " ('.', '.'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('name', 'NN'),\n",
       " ('implies', 'NNS'),\n",
       " (',', ','),\n",
       " ('word', 'NN'),\n",
       " ('vectors', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('vectors', 'NNS'),\n",
       " ('used', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('represent', 'VB'),\n",
       " ('words', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('can', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('considered', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('feature', 'NN'),\n",
       " ('vectors', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('representations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('words', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('the', 'DT'),\n",
       " ('technique', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mapping', 'VBG'),\n",
       " ('words', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('real', 'JJ'),\n",
       " ('vectors', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('called', 'VBN'),\n",
       " ('word', 'NN'),\n",
       " ('embedding', 'NN'),\n",
       " ('.', '.'),\n",
       " ('in', 'IN'),\n",
       " ('recent', 'JJ'),\n",
       " ('years', 'NNS'),\n",
       " (',', ','),\n",
       " ('word', 'NN'),\n",
       " ('embedding', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('gradually', 'RB'),\n",
       " ('become', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('basic', 'JJ'),\n",
       " ('knowledge', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a807e5",
   "metadata": {},
   "source": [
    "# word chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "febd7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac846507",
   "metadata": {},
   "outputs": [],
   "source": [
    "setence = [\n",
    "    (\"the\", \"DT\"),\n",
    "    (\"little\", \"JJ\"),\n",
    "    (\"yellow\", \"JJ\"),\n",
    "    (\"dog\", \"NN\"),\n",
    "    (\"died\", \"VBD\"),\n",
    "]\n",
    "grammer = \"MY_NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp = RegexpParser(grammer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "793fb6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,256.0,168.0\" width=\"256px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"81.25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MY_NP</text></svg><svg width=\"19.2308%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.61538%\" y1=\"20px\" y2=\"48px\" /><svg width=\"30.7692%\" x=\"19.2308%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">little</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.6154%\" y1=\"20px\" y2=\"48px\" /><svg width=\"30.7692%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">yellow</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.3846%\" y1=\"20px\" y2=\"48px\" /><svg width=\"19.2308%\" x=\"80.7692%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">dog</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.3846%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.625%\" y1=\"20px\" y2=\"48px\" /><svg width=\"18.75%\" x=\"81.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">died</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.625%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('MY_NP', [('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN')]), ('died', 'VBD')])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = cp.parse(setence)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a39ac",
   "metadata": {},
   "source": [
    "# named entity recogonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea8a67d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /home/ljj/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('words')\n",
    "# nltk.download('maxent_ne_chunker_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "804b80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5848a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,400.0,168.0\" width=\"400px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"16%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Edison</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8%\" y1=\"20px\" y2=\"48px\" /><svg width=\"12%\" x=\"16%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">went</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22%\" y1=\"20px\" y2=\"48px\" /><svg width=\"8%\" x=\"28%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32%\" y1=\"20px\" y2=\"48px\" /><svg width=\"44%\" x=\"36%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">ORGANIZATION</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Tsinghua</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"20px\" y2=\"48px\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">University</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"58%\" y1=\"20px\" y2=\"48px\" /><svg width=\"14%\" x=\"80%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">today</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6%\" x=\"94%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Edison', 'NNP')]), ('went', 'VBD'), ('to', 'TO'), Tree('ORGANIZATION', [('Tsinghua', 'NNP'), ('University', 'NNP')]), ('today', 'NN'), ('.', '.')])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setence = \"Edison went to Tsinghua University today.\"\n",
    "ne_chunk(pos_tag(word_tokenize(setence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a98b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
